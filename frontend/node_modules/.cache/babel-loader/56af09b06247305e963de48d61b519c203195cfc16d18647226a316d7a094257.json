{"ast":null,"code":"// Remove React testing imports as we're testing API directly\nconst testServerUrl = 'http://192.168.56.1:1234';\nconst LM_STUDIO_ENDPOINTS = {\n  models: '/v1/models',\n  chat: '/v1/chat/completions',\n  completions: '/v1/completions',\n  embeddings: '/v1/embeddings'\n};\nconst DEFAULT_HEADERS = {\n  'Accept': 'application/json',\n  'Content-Type': 'application/json'\n};\n\n// Enhanced network diagnostics\nasync function runNetworkDiagnostics() {\n  const diagnostics = {\n    serverReachable: false,\n    endpoints: {\n      models: false,\n      chat: false,\n      completions: false,\n      embeddings: false\n    },\n    modelList: [],\n    details: [],\n    errors: []\n  };\n  try {\n    // Basic connection test with models endpoint\n    const controller = new AbortController();\n    const timeoutId = setTimeout(() => controller.abort(), 5000);\n    try {\n      // Try direct GET request\n      const response = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.models}`, {\n        method: 'GET',\n        headers: DEFAULT_HEADERS,\n        signal: controller.signal\n      });\n      diagnostics.serverReachable = response.ok;\n      diagnostics.details.push(`Server connection: ${response.ok ? 'Success' : 'Failed'}`);\n      diagnostics.details.push(`Response status: ${response.status} ${response.statusText}`);\n      if (response.ok) {\n        const data = await response.json();\n        diagnostics.endpoints.models = true;\n        diagnostics.modelList = data.data || [];\n        diagnostics.details.push(`Available models: ${diagnostics.modelList.map(m => m.id).join(', ')}`);\n      } else {\n        // Try to get more error details\n        try {\n          const errorText = await response.text();\n          diagnostics.errors.push(`Server response: ${errorText}`);\n        } catch (e) {\n          diagnostics.errors.push('Could not read error response');\n        }\n      }\n    } catch (error) {\n      if (error.name === 'AbortError') {\n        diagnostics.errors.push('Connection timed out after 5 seconds');\n      } else if (error.message === 'Failed to fetch') {\n        diagnostics.errors.push(`Network error: Unable to reach ${testServerUrl}\\nPossible causes:\\n1. Server is not running\\n2. Network/firewall blocking connection\\n3. Incorrect server address`);\n      } else {\n        diagnostics.errors.push(`Connection error: ${error.message}`);\n      }\n    } finally {\n      clearTimeout(timeoutId);\n    }\n\n    // Only test other endpoints if server is reachable\n    if (diagnostics.serverReachable && diagnostics.modelList.length > 0) {\n      // Test chat completions endpoint\n      try {\n        const model = diagnostics.modelList[0].id;\n        const chatResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\n          method: 'POST',\n          headers: DEFAULT_HEADERS,\n          body: JSON.stringify({\n            model,\n            messages: [{\n              role: 'user',\n              content: 'Test'\n            }],\n            stream: false\n          })\n        });\n        diagnostics.endpoints.chat = chatResponse.ok;\n        diagnostics.details.push(`Chat endpoint: ${chatResponse.ok ? 'Available' : 'Not Available'}`);\n        if (!chatResponse.ok) {\n          const errorText = await chatResponse.text();\n          diagnostics.errors.push(`Chat endpoint error: ${errorText}`);\n        }\n      } catch (error) {\n        diagnostics.errors.push(`Chat endpoint error: ${error.message}`);\n      }\n\n      // Test completions endpoint\n      try {\n        const model = diagnostics.modelList[0].id;\n        const completionsResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.completions}`, {\n          method: 'POST',\n          headers: DEFAULT_HEADERS,\n          body: JSON.stringify({\n            model,\n            prompt: 'Test',\n            stream: false\n          })\n        });\n        diagnostics.endpoints.completions = completionsResponse.ok;\n        diagnostics.details.push(`Completions endpoint: ${completionsResponse.ok ? 'Available' : 'Not Available'}`);\n        if (!completionsResponse.ok) {\n          const errorText = await completionsResponse.text();\n          diagnostics.errors.push(`Completions endpoint error: ${errorText}`);\n        }\n      } catch (error) {\n        diagnostics.errors.push(`Completions endpoint error: ${error.message}`);\n      }\n\n      // Test embeddings endpoint\n      try {\n        const embeddingModel = diagnostics.modelList.find(m => m.id.includes('embed'));\n        if (embeddingModel) {\n          const embeddingsResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.embeddings}`, {\n            method: 'POST',\n            headers: DEFAULT_HEADERS,\n            body: JSON.stringify({\n              model: embeddingModel.id,\n              input: 'Test'\n            })\n          });\n          diagnostics.endpoints.embeddings = embeddingsResponse.ok;\n          diagnostics.details.push(`Embeddings endpoint: ${embeddingsResponse.ok ? 'Available' : 'Not Available'}`);\n          if (!embeddingsResponse.ok) {\n            const errorText = await embeddingsResponse.text();\n            diagnostics.errors.push(`Embeddings endpoint error: ${errorText}`);\n          }\n        } else {\n          diagnostics.details.push('No embedding model available');\n        }\n      } catch (error) {\n        diagnostics.errors.push(`Embeddings endpoint error: ${error.message}`);\n      }\n    }\n  } catch (error) {\n    diagnostics.errors.push(`General error: ${error.message}`);\n  }\n  return diagnostics;\n}\n\n// Helper function to run all tests and log results\nexport async function runConnectionTests() {\n  console.log('Starting LM Studio connection tests...');\n  try {\n    var _chatData$choices$, _chatData$choices$$me;\n    // Run network diagnostics first\n    console.log('\\nRunning network diagnostics...');\n    const diagnostics = await runNetworkDiagnostics();\n    if (!diagnostics.serverReachable) {\n      throw new Error(`Unable to connect to LM Studio server at ${testServerUrl}. Please check that:\\n1. LM Studio is running\\n2. Local Server is started\\n3. The server address is correct\\n\\nDiagnostics:\\n${diagnostics.details.join('\\n')}\\n\\nErrors:\\n${diagnostics.errors.join('\\n')}`);\n    }\n\n    // Test 1: Basic Connection & Models List\n    console.log('\\nTesting models endpoint...');\n    const modelResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.models}`);\n    if (!modelResponse.ok) throw new Error(`Server returned ${modelResponse.status}`);\n    const modelData = await modelResponse.json();\n    console.log('Available models:', modelData.data);\n    if (!modelData.data || !modelData.data.length) {\n      throw new Error('No models available. Please load a model in LM Studio first.');\n    }\n    console.log('✅ Models endpoint test passed');\n\n    // Test 2: Simple Chat Request\n    console.log('\\nTesting chat completion...');\n    const chatResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        model: modelData.data[0].id,\n        // Use first available model\n        messages: [{\n          role: 'user',\n          content: 'Hello'\n        }],\n        stream: false\n      })\n    });\n    if (!chatResponse.ok) {\n      const errorData = await chatResponse.text();\n      throw new Error(`Chat request failed: ${chatResponse.status}\\nResponse: ${errorData}`);\n    }\n    const chatData = await chatResponse.json();\n    if (!chatData.choices || !chatData.choices.length) {\n      throw new Error('Chat response missing choices');\n    }\n    console.log('✅ Chat completion test passed');\n    console.log('Response:', (_chatData$choices$ = chatData.choices[0]) === null || _chatData$choices$ === void 0 ? void 0 : (_chatData$choices$$me = _chatData$choices$.message) === null || _chatData$choices$$me === void 0 ? void 0 : _chatData$choices$$me.content);\n\n    // Test 3: Streaming\n    console.log('\\nTesting streaming response...');\n    const streamResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        model: modelData.data[0].id,\n        // Use first available model\n        messages: [{\n          role: 'user',\n          content: 'Hi'\n        }],\n        stream: true\n      })\n    });\n    if (!streamResponse.ok) {\n      const errorData = await streamResponse.text();\n      throw new Error(`Streaming request failed: ${streamResponse.status}\\nResponse: ${errorData}`);\n    }\n    console.log('Reading stream...');\n    const reader = streamResponse.body.getReader();\n    const decoder = new TextDecoder();\n    let streamContent = '';\n    while (true) {\n      const {\n        done,\n        value\n      } = await reader.read();\n      if (done) break;\n      const chunk = decoder.decode(value);\n      const lines = chunk.split('\\n');\n      for (const line of lines) {\n        if (line.trim() && !line.includes('[DONE]')) {\n          try {\n            var _data$choices, _data$choices$, _data$choices$$delta;\n            const jsonStr = line.replace(/^data: /, '');\n            const data = JSON.parse(jsonStr);\n            if ((_data$choices = data.choices) !== null && _data$choices !== void 0 && (_data$choices$ = _data$choices[0]) !== null && _data$choices$ !== void 0 && (_data$choices$$delta = _data$choices$.delta) !== null && _data$choices$$delta !== void 0 && _data$choices$$delta.content) {\n              streamContent += data.choices[0].delta.content;\n              process.stdout.write(data.choices[0].delta.content);\n            }\n          } catch (e) {\n            // Ignore parse errors for non-data lines\n          }\n        }\n      }\n    }\n    console.log('\\n✅ Streaming test passed');\n    console.log('\\n✅ All tests passed successfully!');\n    return true;\n  } catch (error) {\n    console.error('\\n❌ Test failed:', error.message);\n    console.error('Error details:', error);\n    return false;\n  }\n}\n\n// Export diagnostics function for UI\nexport { runNetworkDiagnostics };","map":{"version":3,"names":["testServerUrl","LM_STUDIO_ENDPOINTS","models","chat","completions","embeddings","DEFAULT_HEADERS","runNetworkDiagnostics","diagnostics","serverReachable","endpoints","modelList","details","errors","controller","AbortController","timeoutId","setTimeout","abort","response","fetch","method","headers","signal","ok","push","status","statusText","data","json","map","m","id","join","errorText","text","e","error","name","message","clearTimeout","length","model","chatResponse","body","JSON","stringify","messages","role","content","stream","completionsResponse","prompt","embeddingModel","find","includes","embeddingsResponse","input","runConnectionTests","console","log","_chatData$choices$","_chatData$choices$$me","Error","modelResponse","modelData","errorData","chatData","choices","streamResponse","reader","getReader","decoder","TextDecoder","streamContent","done","value","read","chunk","decode","lines","split","line","trim","_data$choices","_data$choices$","_data$choices$$delta","jsonStr","replace","parse","delta","process","stdout","write"],"sources":["E:/Cline/allm/frontend/src/tests/ChatConnection.test.js"],"sourcesContent":["// Remove React testing imports as we're testing API directly\r\nconst testServerUrl = 'http://192.168.56.1:1234';\r\n\r\nconst LM_STUDIO_ENDPOINTS = {\r\n  models: '/v1/models',\r\n  chat: '/v1/chat/completions',\r\n  completions: '/v1/completions',\r\n  embeddings: '/v1/embeddings'\r\n};\r\n\r\nconst DEFAULT_HEADERS = {\r\n  'Accept': 'application/json',\r\n  'Content-Type': 'application/json'\r\n};\r\n\r\n// Enhanced network diagnostics\r\nasync function runNetworkDiagnostics() {\r\n  const diagnostics = {\r\n    serverReachable: false,\r\n    endpoints: {\r\n      models: false,\r\n      chat: false,\r\n      completions: false,\r\n      embeddings: false\r\n    },\r\n    modelList: [],\r\n    details: [],\r\n    errors: []\r\n  };\r\n\r\n  try {\r\n    // Basic connection test with models endpoint\r\n    const controller = new AbortController();\r\n    const timeoutId = setTimeout(() => controller.abort(), 5000);\r\n    \r\n    try {\r\n      // Try direct GET request\r\n      const response = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.models}`, {\r\n        method: 'GET',\r\n        headers: DEFAULT_HEADERS,\r\n        signal: controller.signal\r\n      });\r\n\r\n      diagnostics.serverReachable = response.ok;\r\n      diagnostics.details.push(`Server connection: ${response.ok ? 'Success' : 'Failed'}`);\r\n      diagnostics.details.push(`Response status: ${response.status} ${response.statusText}`);\r\n      \r\n      if (response.ok) {\r\n        const data = await response.json();\r\n        diagnostics.endpoints.models = true;\r\n        diagnostics.modelList = data.data || [];\r\n        diagnostics.details.push(`Available models: ${diagnostics.modelList.map(m => m.id).join(', ')}`);\r\n      } else {\r\n        // Try to get more error details\r\n        try {\r\n          const errorText = await response.text();\r\n          diagnostics.errors.push(`Server response: ${errorText}`);\r\n        } catch (e) {\r\n          diagnostics.errors.push('Could not read error response');\r\n        }\r\n      }\r\n    } catch (error) {\r\n      if (error.name === 'AbortError') {\r\n        diagnostics.errors.push('Connection timed out after 5 seconds');\r\n      } else if (error.message === 'Failed to fetch') {\r\n        diagnostics.errors.push(`Network error: Unable to reach ${testServerUrl}\\nPossible causes:\\n1. Server is not running\\n2. Network/firewall blocking connection\\n3. Incorrect server address`);\r\n      } else {\r\n        diagnostics.errors.push(`Connection error: ${error.message}`);\r\n      }\r\n    } finally {\r\n      clearTimeout(timeoutId);\r\n    }\r\n\r\n    // Only test other endpoints if server is reachable\r\n    if (diagnostics.serverReachable && diagnostics.modelList.length > 0) {\r\n      // Test chat completions endpoint\r\n      try {\r\n        const model = diagnostics.modelList[0].id;\r\n        const chatResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\r\n          method: 'POST',\r\n          headers: DEFAULT_HEADERS,\r\n          body: JSON.stringify({\r\n            model,\r\n            messages: [{ role: 'user', content: 'Test' }],\r\n            stream: false\r\n          })\r\n        });\r\n        \r\n        diagnostics.endpoints.chat = chatResponse.ok;\r\n        diagnostics.details.push(`Chat endpoint: ${chatResponse.ok ? 'Available' : 'Not Available'}`);\r\n        \r\n        if (!chatResponse.ok) {\r\n          const errorText = await chatResponse.text();\r\n          diagnostics.errors.push(`Chat endpoint error: ${errorText}`);\r\n        }\r\n      } catch (error) {\r\n        diagnostics.errors.push(`Chat endpoint error: ${error.message}`);\r\n      }\r\n\r\n      // Test completions endpoint\r\n      try {\r\n        const model = diagnostics.modelList[0].id;\r\n        const completionsResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.completions}`, {\r\n          method: 'POST',\r\n          headers: DEFAULT_HEADERS,\r\n          body: JSON.stringify({\r\n            model,\r\n            prompt: 'Test',\r\n            stream: false\r\n          })\r\n        });\r\n        \r\n        diagnostics.endpoints.completions = completionsResponse.ok;\r\n        diagnostics.details.push(`Completions endpoint: ${completionsResponse.ok ? 'Available' : 'Not Available'}`);\r\n        \r\n        if (!completionsResponse.ok) {\r\n          const errorText = await completionsResponse.text();\r\n          diagnostics.errors.push(`Completions endpoint error: ${errorText}`);\r\n        }\r\n      } catch (error) {\r\n        diagnostics.errors.push(`Completions endpoint error: ${error.message}`);\r\n      }\r\n\r\n      // Test embeddings endpoint\r\n      try {\r\n        const embeddingModel = diagnostics.modelList.find(m => m.id.includes('embed'));\r\n        if (embeddingModel) {\r\n          const embeddingsResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.embeddings}`, {\r\n            method: 'POST',\r\n            headers: DEFAULT_HEADERS,\r\n            body: JSON.stringify({\r\n              model: embeddingModel.id,\r\n              input: 'Test'\r\n            })\r\n          });\r\n          \r\n          diagnostics.endpoints.embeddings = embeddingsResponse.ok;\r\n          diagnostics.details.push(`Embeddings endpoint: ${embeddingsResponse.ok ? 'Available' : 'Not Available'}`);\r\n          \r\n          if (!embeddingsResponse.ok) {\r\n            const errorText = await embeddingsResponse.text();\r\n            diagnostics.errors.push(`Embeddings endpoint error: ${errorText}`);\r\n          }\r\n        } else {\r\n          diagnostics.details.push('No embedding model available');\r\n        }\r\n      } catch (error) {\r\n        diagnostics.errors.push(`Embeddings endpoint error: ${error.message}`);\r\n      }\r\n    }\r\n\r\n  } catch (error) {\r\n    diagnostics.errors.push(`General error: ${error.message}`);\r\n  }\r\n\r\n  return diagnostics;\r\n}\r\n\r\n// Helper function to run all tests and log results\r\nexport async function runConnectionTests() {\r\n  console.log('Starting LM Studio connection tests...');\r\n  \r\n  try {\r\n    // Run network diagnostics first\r\n    console.log('\\nRunning network diagnostics...');\r\n    const diagnostics = await runNetworkDiagnostics();\r\n    \r\n    if (!diagnostics.serverReachable) {\r\n      throw new Error(`Unable to connect to LM Studio server at ${testServerUrl}. Please check that:\\n1. LM Studio is running\\n2. Local Server is started\\n3. The server address is correct\\n\\nDiagnostics:\\n${diagnostics.details.join('\\n')}\\n\\nErrors:\\n${diagnostics.errors.join('\\n')}`);\r\n    }\r\n    \r\n    // Test 1: Basic Connection & Models List\r\n    console.log('\\nTesting models endpoint...');\r\n    const modelResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.models}`);\r\n    if (!modelResponse.ok) throw new Error(`Server returned ${modelResponse.status}`);\r\n    const modelData = await modelResponse.json();\r\n    console.log('Available models:', modelData.data);\r\n    if (!modelData.data || !modelData.data.length) {\r\n      throw new Error('No models available. Please load a model in LM Studio first.');\r\n    }\r\n    console.log('✅ Models endpoint test passed');\r\n\r\n    // Test 2: Simple Chat Request\r\n    console.log('\\nTesting chat completion...');\r\n    const chatResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\r\n      method: 'POST',\r\n      headers: { 'Content-Type': 'application/json' },\r\n      body: JSON.stringify({\r\n        model: modelData.data[0].id, // Use first available model\r\n        messages: [{ role: 'user', content: 'Hello' }],\r\n        stream: false\r\n      })\r\n    });\r\n    \r\n    if (!chatResponse.ok) {\r\n      const errorData = await chatResponse.text();\r\n      throw new Error(`Chat request failed: ${chatResponse.status}\\nResponse: ${errorData}`);\r\n    }\r\n    \r\n    const chatData = await chatResponse.json();\r\n    if (!chatData.choices || !chatData.choices.length) {\r\n      throw new Error('Chat response missing choices');\r\n    }\r\n    console.log('✅ Chat completion test passed');\r\n    console.log('Response:', chatData.choices[0]?.message?.content);\r\n\r\n    // Test 3: Streaming\r\n    console.log('\\nTesting streaming response...');\r\n    const streamResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\r\n      method: 'POST',\r\n      headers: { 'Content-Type': 'application/json' },\r\n      body: JSON.stringify({\r\n        model: modelData.data[0].id, // Use first available model\r\n        messages: [{ role: 'user', content: 'Hi' }],\r\n        stream: true\r\n      })\r\n    });\r\n\r\n    if (!streamResponse.ok) {\r\n      const errorData = await streamResponse.text();\r\n      throw new Error(`Streaming request failed: ${streamResponse.status}\\nResponse: ${errorData}`);\r\n    }\r\n\r\n    console.log('Reading stream...');\r\n    const reader = streamResponse.body.getReader();\r\n    const decoder = new TextDecoder();\r\n    let streamContent = '';\r\n\r\n    while (true) {\r\n      const { done, value } = await reader.read();\r\n      if (done) break;\r\n      \r\n      const chunk = decoder.decode(value);\r\n      const lines = chunk.split('\\n');\r\n      \r\n      for (const line of lines) {\r\n        if (line.trim() && !line.includes('[DONE]')) {\r\n          try {\r\n            const jsonStr = line.replace(/^data: /, '');\r\n            const data = JSON.parse(jsonStr);\r\n            if (data.choices?.[0]?.delta?.content) {\r\n              streamContent += data.choices[0].delta.content;\r\n              process.stdout.write(data.choices[0].delta.content);\r\n            }\r\n          } catch (e) {\r\n            // Ignore parse errors for non-data lines\r\n          }\r\n        }\r\n      }\r\n    }\r\n    console.log('\\n✅ Streaming test passed');\r\n\r\n    console.log('\\n✅ All tests passed successfully!');\r\n    return true;\r\n  } catch (error) {\r\n    console.error('\\n❌ Test failed:', error.message);\r\n    console.error('Error details:', error);\r\n    return false;\r\n  }\r\n}\r\n\r\n// Export diagnostics function for UI\r\nexport { runNetworkDiagnostics }; "],"mappings":"AAAA;AACA,MAAMA,aAAa,GAAG,0BAA0B;AAEhD,MAAMC,mBAAmB,GAAG;EAC1BC,MAAM,EAAE,YAAY;EACpBC,IAAI,EAAE,sBAAsB;EAC5BC,WAAW,EAAE,iBAAiB;EAC9BC,UAAU,EAAE;AACd,CAAC;AAED,MAAMC,eAAe,GAAG;EACtB,QAAQ,EAAE,kBAAkB;EAC5B,cAAc,EAAE;AAClB,CAAC;;AAED;AACA,eAAeC,qBAAqBA,CAAA,EAAG;EACrC,MAAMC,WAAW,GAAG;IAClBC,eAAe,EAAE,KAAK;IACtBC,SAAS,EAAE;MACTR,MAAM,EAAE,KAAK;MACbC,IAAI,EAAE,KAAK;MACXC,WAAW,EAAE,KAAK;MAClBC,UAAU,EAAE;IACd,CAAC;IACDM,SAAS,EAAE,EAAE;IACbC,OAAO,EAAE,EAAE;IACXC,MAAM,EAAE;EACV,CAAC;EAED,IAAI;IACF;IACA,MAAMC,UAAU,GAAG,IAAIC,eAAe,CAAC,CAAC;IACxC,MAAMC,SAAS,GAAGC,UAAU,CAAC,MAAMH,UAAU,CAACI,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC;IAE5D,IAAI;MACF;MACA,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACC,MAAM,EAAE,EAAE;QAC5EmB,MAAM,EAAE,KAAK;QACbC,OAAO,EAAEhB,eAAe;QACxBiB,MAAM,EAAET,UAAU,CAACS;MACrB,CAAC,CAAC;MAEFf,WAAW,CAACC,eAAe,GAAGU,QAAQ,CAACK,EAAE;MACzChB,WAAW,CAACI,OAAO,CAACa,IAAI,CAAC,sBAAsBN,QAAQ,CAACK,EAAE,GAAG,SAAS,GAAG,QAAQ,EAAE,CAAC;MACpFhB,WAAW,CAACI,OAAO,CAACa,IAAI,CAAC,oBAAoBN,QAAQ,CAACO,MAAM,IAAIP,QAAQ,CAACQ,UAAU,EAAE,CAAC;MAEtF,IAAIR,QAAQ,CAACK,EAAE,EAAE;QACf,MAAMI,IAAI,GAAG,MAAMT,QAAQ,CAACU,IAAI,CAAC,CAAC;QAClCrB,WAAW,CAACE,SAAS,CAACR,MAAM,GAAG,IAAI;QACnCM,WAAW,CAACG,SAAS,GAAGiB,IAAI,CAACA,IAAI,IAAI,EAAE;QACvCpB,WAAW,CAACI,OAAO,CAACa,IAAI,CAAC,qBAAqBjB,WAAW,CAACG,SAAS,CAACmB,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACC,EAAE,CAAC,CAACC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC;MAClG,CAAC,MAAM;QACL;QACA,IAAI;UACF,MAAMC,SAAS,GAAG,MAAMf,QAAQ,CAACgB,IAAI,CAAC,CAAC;UACvC3B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,oBAAoBS,SAAS,EAAE,CAAC;QAC1D,CAAC,CAAC,OAAOE,CAAC,EAAE;UACV5B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,+BAA+B,CAAC;QAC1D;MACF;IACF,CAAC,CAAC,OAAOY,KAAK,EAAE;MACd,IAAIA,KAAK,CAACC,IAAI,KAAK,YAAY,EAAE;QAC/B9B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,sCAAsC,CAAC;MACjE,CAAC,MAAM,IAAIY,KAAK,CAACE,OAAO,KAAK,iBAAiB,EAAE;QAC9C/B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,kCAAkCzB,aAAa,oHAAoH,CAAC;MAC9L,CAAC,MAAM;QACLQ,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,qBAAqBY,KAAK,CAACE,OAAO,EAAE,CAAC;MAC/D;IACF,CAAC,SAAS;MACRC,YAAY,CAACxB,SAAS,CAAC;IACzB;;IAEA;IACA,IAAIR,WAAW,CAACC,eAAe,IAAID,WAAW,CAACG,SAAS,CAAC8B,MAAM,GAAG,CAAC,EAAE;MACnE;MACA,IAAI;QACF,MAAMC,KAAK,GAAGlC,WAAW,CAACG,SAAS,CAAC,CAAC,CAAC,CAACqB,EAAE;QACzC,MAAMW,YAAY,GAAG,MAAMvB,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACE,IAAI,EAAE,EAAE;UAC9EkB,MAAM,EAAE,MAAM;UACdC,OAAO,EAAEhB,eAAe;UACxBsC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;YACnBJ,KAAK;YACLK,QAAQ,EAAE,CAAC;cAAEC,IAAI,EAAE,MAAM;cAAEC,OAAO,EAAE;YAAO,CAAC,CAAC;YAC7CC,MAAM,EAAE;UACV,CAAC;QACH,CAAC,CAAC;QAEF1C,WAAW,CAACE,SAAS,CAACP,IAAI,GAAGwC,YAAY,CAACnB,EAAE;QAC5ChB,WAAW,CAACI,OAAO,CAACa,IAAI,CAAC,kBAAkBkB,YAAY,CAACnB,EAAE,GAAG,WAAW,GAAG,eAAe,EAAE,CAAC;QAE7F,IAAI,CAACmB,YAAY,CAACnB,EAAE,EAAE;UACpB,MAAMU,SAAS,GAAG,MAAMS,YAAY,CAACR,IAAI,CAAC,CAAC;UAC3C3B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,wBAAwBS,SAAS,EAAE,CAAC;QAC9D;MACF,CAAC,CAAC,OAAOG,KAAK,EAAE;QACd7B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,wBAAwBY,KAAK,CAACE,OAAO,EAAE,CAAC;MAClE;;MAEA;MACA,IAAI;QACF,MAAMG,KAAK,GAAGlC,WAAW,CAACG,SAAS,CAAC,CAAC,CAAC,CAACqB,EAAE;QACzC,MAAMmB,mBAAmB,GAAG,MAAM/B,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACG,WAAW,EAAE,EAAE;UAC5FiB,MAAM,EAAE,MAAM;UACdC,OAAO,EAAEhB,eAAe;UACxBsC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;YACnBJ,KAAK;YACLU,MAAM,EAAE,MAAM;YACdF,MAAM,EAAE;UACV,CAAC;QACH,CAAC,CAAC;QAEF1C,WAAW,CAACE,SAAS,CAACN,WAAW,GAAG+C,mBAAmB,CAAC3B,EAAE;QAC1DhB,WAAW,CAACI,OAAO,CAACa,IAAI,CAAC,yBAAyB0B,mBAAmB,CAAC3B,EAAE,GAAG,WAAW,GAAG,eAAe,EAAE,CAAC;QAE3G,IAAI,CAAC2B,mBAAmB,CAAC3B,EAAE,EAAE;UAC3B,MAAMU,SAAS,GAAG,MAAMiB,mBAAmB,CAAChB,IAAI,CAAC,CAAC;UAClD3B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,+BAA+BS,SAAS,EAAE,CAAC;QACrE;MACF,CAAC,CAAC,OAAOG,KAAK,EAAE;QACd7B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,+BAA+BY,KAAK,CAACE,OAAO,EAAE,CAAC;MACzE;;MAEA;MACA,IAAI;QACF,MAAMc,cAAc,GAAG7C,WAAW,CAACG,SAAS,CAAC2C,IAAI,CAACvB,CAAC,IAAIA,CAAC,CAACC,EAAE,CAACuB,QAAQ,CAAC,OAAO,CAAC,CAAC;QAC9E,IAAIF,cAAc,EAAE;UAClB,MAAMG,kBAAkB,GAAG,MAAMpC,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACI,UAAU,EAAE,EAAE;YAC1FgB,MAAM,EAAE,MAAM;YACdC,OAAO,EAAEhB,eAAe;YACxBsC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;cACnBJ,KAAK,EAAEW,cAAc,CAACrB,EAAE;cACxByB,KAAK,EAAE;YACT,CAAC;UACH,CAAC,CAAC;UAEFjD,WAAW,CAACE,SAAS,CAACL,UAAU,GAAGmD,kBAAkB,CAAChC,EAAE;UACxDhB,WAAW,CAACI,OAAO,CAACa,IAAI,CAAC,wBAAwB+B,kBAAkB,CAAChC,EAAE,GAAG,WAAW,GAAG,eAAe,EAAE,CAAC;UAEzG,IAAI,CAACgC,kBAAkB,CAAChC,EAAE,EAAE;YAC1B,MAAMU,SAAS,GAAG,MAAMsB,kBAAkB,CAACrB,IAAI,CAAC,CAAC;YACjD3B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,8BAA8BS,SAAS,EAAE,CAAC;UACpE;QACF,CAAC,MAAM;UACL1B,WAAW,CAACI,OAAO,CAACa,IAAI,CAAC,8BAA8B,CAAC;QAC1D;MACF,CAAC,CAAC,OAAOY,KAAK,EAAE;QACd7B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,8BAA8BY,KAAK,CAACE,OAAO,EAAE,CAAC;MACxE;IACF;EAEF,CAAC,CAAC,OAAOF,KAAK,EAAE;IACd7B,WAAW,CAACK,MAAM,CAACY,IAAI,CAAC,kBAAkBY,KAAK,CAACE,OAAO,EAAE,CAAC;EAC5D;EAEA,OAAO/B,WAAW;AACpB;;AAEA;AACA,OAAO,eAAekD,kBAAkBA,CAAA,EAAG;EACzCC,OAAO,CAACC,GAAG,CAAC,wCAAwC,CAAC;EAErD,IAAI;IAAA,IAAAC,kBAAA,EAAAC,qBAAA;IACF;IACAH,OAAO,CAACC,GAAG,CAAC,kCAAkC,CAAC;IAC/C,MAAMpD,WAAW,GAAG,MAAMD,qBAAqB,CAAC,CAAC;IAEjD,IAAI,CAACC,WAAW,CAACC,eAAe,EAAE;MAChC,MAAM,IAAIsD,KAAK,CAAC,4CAA4C/D,aAAa,gIAAgIQ,WAAW,CAACI,OAAO,CAACqB,IAAI,CAAC,IAAI,CAAC,gBAAgBzB,WAAW,CAACK,MAAM,CAACoB,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC;IACzR;;IAEA;IACA0B,OAAO,CAACC,GAAG,CAAC,8BAA8B,CAAC;IAC3C,MAAMI,aAAa,GAAG,MAAM5C,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACC,MAAM,EAAE,CAAC;IAClF,IAAI,CAAC8D,aAAa,CAACxC,EAAE,EAAE,MAAM,IAAIuC,KAAK,CAAC,mBAAmBC,aAAa,CAACtC,MAAM,EAAE,CAAC;IACjF,MAAMuC,SAAS,GAAG,MAAMD,aAAa,CAACnC,IAAI,CAAC,CAAC;IAC5C8B,OAAO,CAACC,GAAG,CAAC,mBAAmB,EAAEK,SAAS,CAACrC,IAAI,CAAC;IAChD,IAAI,CAACqC,SAAS,CAACrC,IAAI,IAAI,CAACqC,SAAS,CAACrC,IAAI,CAACa,MAAM,EAAE;MAC7C,MAAM,IAAIsB,KAAK,CAAC,8DAA8D,CAAC;IACjF;IACAJ,OAAO,CAACC,GAAG,CAAC,+BAA+B,CAAC;;IAE5C;IACAD,OAAO,CAACC,GAAG,CAAC,8BAA8B,CAAC;IAC3C,MAAMjB,YAAY,GAAG,MAAMvB,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACE,IAAI,EAAE,EAAE;MAC9EkB,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QAAE,cAAc,EAAE;MAAmB,CAAC;MAC/CsB,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBJ,KAAK,EAAEuB,SAAS,CAACrC,IAAI,CAAC,CAAC,CAAC,CAACI,EAAE;QAAE;QAC7Be,QAAQ,EAAE,CAAC;UAAEC,IAAI,EAAE,MAAM;UAAEC,OAAO,EAAE;QAAQ,CAAC,CAAC;QAC9CC,MAAM,EAAE;MACV,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAACP,YAAY,CAACnB,EAAE,EAAE;MACpB,MAAM0C,SAAS,GAAG,MAAMvB,YAAY,CAACR,IAAI,CAAC,CAAC;MAC3C,MAAM,IAAI4B,KAAK,CAAC,wBAAwBpB,YAAY,CAACjB,MAAM,eAAewC,SAAS,EAAE,CAAC;IACxF;IAEA,MAAMC,QAAQ,GAAG,MAAMxB,YAAY,CAACd,IAAI,CAAC,CAAC;IAC1C,IAAI,CAACsC,QAAQ,CAACC,OAAO,IAAI,CAACD,QAAQ,CAACC,OAAO,CAAC3B,MAAM,EAAE;MACjD,MAAM,IAAIsB,KAAK,CAAC,+BAA+B,CAAC;IAClD;IACAJ,OAAO,CAACC,GAAG,CAAC,+BAA+B,CAAC;IAC5CD,OAAO,CAACC,GAAG,CAAC,WAAW,GAAAC,kBAAA,GAAEM,QAAQ,CAACC,OAAO,CAAC,CAAC,CAAC,cAAAP,kBAAA,wBAAAC,qBAAA,GAAnBD,kBAAA,CAAqBtB,OAAO,cAAAuB,qBAAA,uBAA5BA,qBAAA,CAA8Bb,OAAO,CAAC;;IAE/D;IACAU,OAAO,CAACC,GAAG,CAAC,iCAAiC,CAAC;IAC9C,MAAMS,cAAc,GAAG,MAAMjD,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACE,IAAI,EAAE,EAAE;MAChFkB,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QAAE,cAAc,EAAE;MAAmB,CAAC;MAC/CsB,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBJ,KAAK,EAAEuB,SAAS,CAACrC,IAAI,CAAC,CAAC,CAAC,CAACI,EAAE;QAAE;QAC7Be,QAAQ,EAAE,CAAC;UAAEC,IAAI,EAAE,MAAM;UAAEC,OAAO,EAAE;QAAK,CAAC,CAAC;QAC3CC,MAAM,EAAE;MACV,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAACmB,cAAc,CAAC7C,EAAE,EAAE;MACtB,MAAM0C,SAAS,GAAG,MAAMG,cAAc,CAAClC,IAAI,CAAC,CAAC;MAC7C,MAAM,IAAI4B,KAAK,CAAC,6BAA6BM,cAAc,CAAC3C,MAAM,eAAewC,SAAS,EAAE,CAAC;IAC/F;IAEAP,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;IAChC,MAAMU,MAAM,GAAGD,cAAc,CAACzB,IAAI,CAAC2B,SAAS,CAAC,CAAC;IAC9C,MAAMC,OAAO,GAAG,IAAIC,WAAW,CAAC,CAAC;IACjC,IAAIC,aAAa,GAAG,EAAE;IAEtB,OAAO,IAAI,EAAE;MACX,MAAM;QAAEC,IAAI;QAAEC;MAAM,CAAC,GAAG,MAAMN,MAAM,CAACO,IAAI,CAAC,CAAC;MAC3C,IAAIF,IAAI,EAAE;MAEV,MAAMG,KAAK,GAAGN,OAAO,CAACO,MAAM,CAACH,KAAK,CAAC;MACnC,MAAMI,KAAK,GAAGF,KAAK,CAACG,KAAK,CAAC,IAAI,CAAC;MAE/B,KAAK,MAAMC,IAAI,IAAIF,KAAK,EAAE;QACxB,IAAIE,IAAI,CAACC,IAAI,CAAC,CAAC,IAAI,CAACD,IAAI,CAAC3B,QAAQ,CAAC,QAAQ,CAAC,EAAE;UAC3C,IAAI;YAAA,IAAA6B,aAAA,EAAAC,cAAA,EAAAC,oBAAA;YACF,MAAMC,OAAO,GAAGL,IAAI,CAACM,OAAO,CAAC,SAAS,EAAE,EAAE,CAAC;YAC3C,MAAM5D,IAAI,GAAGiB,IAAI,CAAC4C,KAAK,CAACF,OAAO,CAAC;YAChC,KAAAH,aAAA,GAAIxD,IAAI,CAACwC,OAAO,cAAAgB,aAAA,gBAAAC,cAAA,GAAZD,aAAA,CAAe,CAAC,CAAC,cAAAC,cAAA,gBAAAC,oBAAA,GAAjBD,cAAA,CAAmBK,KAAK,cAAAJ,oBAAA,eAAxBA,oBAAA,CAA0BrC,OAAO,EAAE;cACrCyB,aAAa,IAAI9C,IAAI,CAACwC,OAAO,CAAC,CAAC,CAAC,CAACsB,KAAK,CAACzC,OAAO;cAC9C0C,OAAO,CAACC,MAAM,CAACC,KAAK,CAACjE,IAAI,CAACwC,OAAO,CAAC,CAAC,CAAC,CAACsB,KAAK,CAACzC,OAAO,CAAC;YACrD;UACF,CAAC,CAAC,OAAOb,CAAC,EAAE;YACV;UAAA;QAEJ;MACF;IACF;IACAuB,OAAO,CAACC,GAAG,CAAC,2BAA2B,CAAC;IAExCD,OAAO,CAACC,GAAG,CAAC,oCAAoC,CAAC;IACjD,OAAO,IAAI;EACb,CAAC,CAAC,OAAOvB,KAAK,EAAE;IACdsB,OAAO,CAACtB,KAAK,CAAC,kBAAkB,EAAEA,KAAK,CAACE,OAAO,CAAC;IAChDoB,OAAO,CAACtB,KAAK,CAAC,gBAAgB,EAAEA,KAAK,CAAC;IACtC,OAAO,KAAK;EACd;AACF;;AAEA;AACA,SAAS9B,qBAAqB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}