{"ast":null,"code":"// Remove React testing imports as we're testing API directly\nconst testServerUrl = 'http://192.168.50.89:1234';\nconst LM_STUDIO_ENDPOINTS = {\n  models: '/v1/models',\n  chat: '/v1/chat/completions',\n  completions: '/v1/completions',\n  embeddings: '/v1/embeddings'\n};\nconst DEFAULT_HEADERS = {\n  'Accept': 'application/json',\n  'Content-Type': 'application/json'\n};\n\n// Enhanced network diagnostics\nasync function runNetworkDiagnostics() {\n  const diagnostics = {\n    serverReachable: false,\n    endpoints: {\n      models: false,\n      chat: false,\n      completions: false,\n      embeddings: false\n    },\n    modelList: [],\n    details: [],\n    errors: []\n  };\n  try {\n    // Basic connection test with models endpoint\n    const controller = new AbortController();\n    const timeoutId = setTimeout(() => controller.abort(), 5000);\n    try {\n      // Try direct GET request\n      const response = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.models}`, {\n        method: 'GET',\n        headers: DEFAULT_HEADERS,\n        signal: controller.signal\n      });\n      clearTimeout(timeoutId);\n      diagnostics.serverReachable = response.ok;\n      diagnostics.details.push(`Server connection: ${response.ok ? 'Success' : 'Failed'}`);\n      diagnostics.details.push(`Response status: ${response.status} ${response.statusText}`);\n      if (response.ok) {\n        const data = await response.json();\n        diagnostics.endpoints.models = true;\n        diagnostics.modelList = data.data || [];\n        diagnostics.details.push(`Available models: ${diagnostics.modelList.map(m => m.id).join(', ')}`);\n      } else {\n        // Try to get more error details\n        try {\n          const errorText = await response.text();\n          diagnostics.errors.push(`Server response: ${errorText}`);\n        } catch (e) {\n          diagnostics.errors.push('Could not read error response');\n        }\n      }\n    } catch (error) {\n      if (error.name === 'AbortError') {\n        diagnostics.errors.push('Connection timed out after 5 seconds');\n      } else if (error.message === 'Failed to fetch') {\n        diagnostics.errors.push(`Network error: Unable to reach ${testServerUrl}\\nPossible causes:\\n1. Server is not running\\n2. Network/firewall blocking connection\\n3. Incorrect server address`);\n      } else {\n        diagnostics.errors.push(`Connection error: ${error.message}`);\n      }\n    }\n\n    // Only test other endpoints if server is reachable\n    if (diagnostics.serverReachable && diagnostics.modelList.length > 0) {\n      const model = diagnostics.modelList[0].id;\n\n      // Test chat completions endpoint\n      try {\n        const chatResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\n          method: 'POST',\n          headers: DEFAULT_HEADERS,\n          body: JSON.stringify({\n            model,\n            messages: [{\n              role: 'user',\n              content: 'Test'\n            }],\n            stream: false,\n            max_tokens: 1\n          })\n        });\n        diagnostics.endpoints.chat = chatResponse.ok;\n        diagnostics.details.push(`Chat endpoint: ${chatResponse.ok ? 'Available' : 'Not Available'}`);\n        if (!chatResponse.ok) {\n          const errorText = await chatResponse.text();\n          diagnostics.errors.push(`Chat endpoint error: ${errorText}`);\n        }\n      } catch (error) {\n        diagnostics.errors.push(`Chat endpoint error: ${error.message}`);\n      }\n\n      // Test completions endpoint\n      try {\n        const completionsResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.completions}`, {\n          method: 'POST',\n          headers: DEFAULT_HEADERS,\n          body: JSON.stringify({\n            model,\n            prompt: 'Test',\n            stream: false,\n            max_tokens: 1\n          })\n        });\n        diagnostics.endpoints.completions = completionsResponse.ok;\n        diagnostics.details.push(`Completions endpoint: ${completionsResponse.ok ? 'Available' : 'Not Available'}`);\n        if (!completionsResponse.ok) {\n          const errorText = await completionsResponse.text();\n          diagnostics.errors.push(`Completions endpoint error: ${errorText}`);\n        }\n      } catch (error) {\n        diagnostics.errors.push(`Completions endpoint error: ${error.message}`);\n      }\n\n      // Test embeddings endpoint\n      try {\n        const embeddingModel = diagnostics.modelList.find(m => m.id.includes('embed'));\n        if (embeddingModel) {\n          const embeddingsResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.embeddings}`, {\n            method: 'POST',\n            headers: DEFAULT_HEADERS,\n            body: JSON.stringify({\n              model: embeddingModel.id,\n              input: 'Test'\n            })\n          });\n          diagnostics.endpoints.embeddings = embeddingsResponse.ok;\n          diagnostics.details.push(`Embeddings endpoint: ${embeddingsResponse.ok ? 'Available' : 'Not Available'}`);\n          if (!embeddingsResponse.ok) {\n            const errorText = await embeddingsResponse.text();\n            diagnostics.errors.push(`Embeddings endpoint error: ${errorText}`);\n          }\n        } else {\n          diagnostics.details.push('No embedding model available');\n        }\n      } catch (error) {\n        diagnostics.errors.push(`Embeddings endpoint error: ${error.message}`);\n      }\n    }\n  } catch (error) {\n    diagnostics.errors.push(`General error: ${error.message}`);\n  }\n  return diagnostics;\n}\n\n// Helper function to run all tests and log results\nasync function runConnectionTests() {\n  console.log('Starting LM Studio connection tests...');\n  try {\n    var _chatData$choices$, _chatData$choices$$me;\n    // Run network diagnostics first\n    console.log('\\nRunning network diagnostics...');\n    const diagnostics = await runNetworkDiagnostics();\n    if (!diagnostics.serverReachable) {\n      throw new Error(`Unable to connect to LM Studio server at ${testServerUrl}. Please check that:\\n1. LM Studio is running\\n2. Local Server is started\\n3. The server address is correct\\n\\nDiagnostics:\\n${diagnostics.details.join('\\n')}\\n\\nErrors:\\n${diagnostics.errors.join('\\n')}`);\n    }\n\n    // Test 1: Basic Connection & Models List\n    console.log('\\nTesting models endpoint...');\n    const modelResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.models}`);\n    if (!modelResponse.ok) throw new Error(`Server returned ${modelResponse.status}`);\n    const modelData = await modelResponse.json();\n    console.log('Available models:', modelData.data);\n    if (!modelData.data || !modelData.data.length) {\n      throw new Error('No models available. Please load a model in LM Studio first.');\n    }\n    console.log('✅ Models endpoint test passed');\n\n    // Test 2: Simple Chat Request\n    console.log('\\nTesting chat completion...');\n    const chatResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        model: modelData.data[0].id,\n        // Use first available model\n        messages: [{\n          role: 'user',\n          content: 'Hello'\n        }],\n        stream: false\n      })\n    });\n    if (!chatResponse.ok) {\n      const errorData = await chatResponse.text();\n      throw new Error(`Chat request failed: ${chatResponse.status}\\nResponse: ${errorData}`);\n    }\n    const chatData = await chatResponse.json();\n    if (!chatData.choices || !chatData.choices.length) {\n      throw new Error('Chat response missing choices');\n    }\n    console.log('✅ Chat completion test passed');\n    console.log('Response:', (_chatData$choices$ = chatData.choices[0]) === null || _chatData$choices$ === void 0 ? void 0 : (_chatData$choices$$me = _chatData$choices$.message) === null || _chatData$choices$$me === void 0 ? void 0 : _chatData$choices$$me.content);\n\n    // Test 3: Streaming\n    console.log('\\nTesting streaming response...');\n    const streamResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        model: modelData.data[0].id,\n        // Use first available model\n        messages: [{\n          role: 'user',\n          content: 'Hi'\n        }],\n        stream: true\n      })\n    });\n    if (!streamResponse.ok) {\n      const errorData = await streamResponse.text();\n      throw new Error(`Streaming request failed: ${streamResponse.status}\\nResponse: ${errorData}`);\n    }\n    console.log('Reading stream...');\n    const reader = streamResponse.body.getReader();\n    const decoder = new TextDecoder();\n    let streamContent = '';\n    while (true) {\n      const {\n        done,\n        value\n      } = await reader.read();\n      if (done) break;\n      const chunk = decoder.decode(value);\n      const lines = chunk.split('\\n');\n      for (const line of lines) {\n        if (line.trim() && !line.includes('[DONE]')) {\n          try {\n            var _data$choices, _data$choices$, _data$choices$$delta;\n            const jsonStr = line.replace(/^data: /, '');\n            const data = JSON.parse(jsonStr);\n            if ((_data$choices = data.choices) !== null && _data$choices !== void 0 && (_data$choices$ = _data$choices[0]) !== null && _data$choices$ !== void 0 && (_data$choices$$delta = _data$choices$.delta) !== null && _data$choices$$delta !== void 0 && _data$choices$$delta.content) {\n              streamContent += data.choices[0].delta.content;\n              process.stdout.write(data.choices[0].delta.content);\n            }\n          } catch (e) {\n            // Ignore parse errors for non-data lines\n          }\n        }\n      }\n    }\n    console.log('\\n✅ Streaming test passed');\n    console.log('\\n✅ All tests passed successfully!');\n    return true;\n  } catch (error) {\n    console.error('\\n❌ Test failed:', error.message);\n    console.error('Error details:', error);\n    return false;\n  }\n}\ndescribe('ChatConnection', () => {\n  var _s = $RefreshSig$(),\n    _s2 = $RefreshSig$();\n  _s(beforeEach(_s(() => {\n    _s();\n    // Reset fetch mocks before each test\n    global.fetch = jest.fn();\n    jest.useFakeTimers();\n  }, \"XJ2oOTOFkMkpHwoj5vtSyjk9cTk=\", true)), \"XJ2oOTOFkMkpHwoj5vtSyjk9cTk=\", true);\n  _s2(afterEach(_s2(() => {\n    _s2();\n    jest.useRealTimers();\n  }, \"SorhAKJ5LalUUOIFAWOBDEomlvs=\", true)), \"SorhAKJ5LalUUOIFAWOBDEomlvs=\", true);\n  it('should run network diagnostics successfully', async () => {\n    // Mock successful responses\n    global.fetch.mockImplementation(url => {\n      if (url.includes('/v1/models')) {\n        return Promise.resolve({\n          ok: true,\n          json: () => Promise.resolve({\n            data: [{\n              id: 'test-model'\n            }]\n          }),\n          text: () => Promise.resolve(''),\n          status: 200,\n          statusText: 'OK'\n        });\n      }\n      return Promise.resolve({\n        ok: true,\n        json: () => Promise.resolve({}),\n        text: () => Promise.resolve(''),\n        status: 200,\n        statusText: 'OK'\n      });\n    });\n    const diagnostics = await runNetworkDiagnostics();\n    expect(diagnostics.serverReachable).toBe(true);\n    expect(diagnostics.endpoints.models).toBe(true);\n    expect(diagnostics.modelList).toHaveLength(1);\n    expect(diagnostics.modelList[0].id).toBe('test-model');\n  });\n  it('should handle server connection failure', async () => {\n    // Mock failed connection\n    global.fetch.mockRejectedValue(new Error('Failed to fetch'));\n    const diagnostics = await runNetworkDiagnostics();\n    expect(diagnostics.serverReachable).toBe(false);\n    expect(diagnostics.errors).toHaveLength(1);\n    expect(diagnostics.errors[0]).toContain('Network error: Unable to reach');\n  });\n  it('should handle timeout', async () => {\n    // Mock timeout\n    global.fetch.mockImplementation((_url, options) => {\n      return new Promise((resolve, reject) => {\n        const timeoutId = setTimeout(() => {\n          resolve({\n            ok: false,\n            status: 408,\n            statusText: 'Request Timeout'\n          });\n        }, 6000);\n\n        // Handle abort signal\n        if (options !== null && options !== void 0 && options.signal) {\n          options.signal.addEventListener('abort', () => {\n            clearTimeout(timeoutId);\n            reject(new Error('AbortError'));\n          });\n        }\n      });\n    });\n    const diagnosticsPromise = runNetworkDiagnostics();\n    jest.advanceTimersByTime(5000); // Advance just to the timeout\n    const diagnostics = await diagnosticsPromise;\n    expect(diagnostics.serverReachable).toBe(false);\n    expect(diagnostics.errors).toHaveLength(1);\n    expect(diagnostics.errors[0]).toBe('Connection timed out after 5 seconds');\n  });\n});\nmodule.exports = {\n  runConnectionTests,\n  runNetworkDiagnostics\n};","map":{"version":3,"names":["testServerUrl","LM_STUDIO_ENDPOINTS","models","chat","completions","embeddings","DEFAULT_HEADERS","runNetworkDiagnostics","diagnostics","serverReachable","endpoints","modelList","details","errors","controller","AbortController","timeoutId","setTimeout","abort","response","fetch","method","headers","signal","clearTimeout","ok","push","status","statusText","data","json","map","m","id","join","errorText","text","e","error","name","message","length","model","chatResponse","body","JSON","stringify","messages","role","content","stream","max_tokens","completionsResponse","prompt","embeddingModel","find","includes","embeddingsResponse","input","runConnectionTests","console","log","_chatData$choices$","_chatData$choices$$me","Error","modelResponse","modelData","errorData","chatData","choices","streamResponse","reader","getReader","decoder","TextDecoder","streamContent","done","value","read","chunk","decode","lines","split","line","trim","_data$choices","_data$choices$","_data$choices$$delta","jsonStr","replace","parse","delta","process","stdout","write","describe","_s","$RefreshSig$","_s2","beforeEach","global","jest","fn","useFakeTimers","afterEach","useRealTimers","it","mockImplementation","url","Promise","resolve","expect","toBe","toHaveLength","mockRejectedValue","toContain","_url","options","reject","addEventListener","diagnosticsPromise","advanceTimersByTime","module","exports"],"sources":["E:/Cline/allm/frontend/src/tests/ChatConnection.test.js"],"sourcesContent":["// Remove React testing imports as we're testing API directly\r\nconst testServerUrl = 'http://192.168.50.89:1234';\r\n\r\nconst LM_STUDIO_ENDPOINTS = {\r\n  models: '/v1/models',\r\n  chat: '/v1/chat/completions',\r\n  completions: '/v1/completions',\r\n  embeddings: '/v1/embeddings'\r\n};\r\n\r\nconst DEFAULT_HEADERS = {\r\n  'Accept': 'application/json',\r\n  'Content-Type': 'application/json'\r\n};\r\n\r\n// Enhanced network diagnostics\r\nasync function runNetworkDiagnostics() {\r\n  const diagnostics = {\r\n    serverReachable: false,\r\n    endpoints: {\r\n      models: false,\r\n      chat: false,\r\n      completions: false,\r\n      embeddings: false\r\n    },\r\n    modelList: [],\r\n    details: [],\r\n    errors: []\r\n  };\r\n\r\n  try {\r\n    // Basic connection test with models endpoint\r\n    const controller = new AbortController();\r\n    const timeoutId = setTimeout(() => controller.abort(), 5000);\r\n    \r\n    try {\r\n      // Try direct GET request\r\n      const response = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.models}`, {\r\n        method: 'GET',\r\n        headers: DEFAULT_HEADERS,\r\n        signal: controller.signal\r\n      });\r\n\r\n      clearTimeout(timeoutId);\r\n\r\n      diagnostics.serverReachable = response.ok;\r\n      diagnostics.details.push(`Server connection: ${response.ok ? 'Success' : 'Failed'}`);\r\n      diagnostics.details.push(`Response status: ${response.status} ${response.statusText}`);\r\n      \r\n      if (response.ok) {\r\n        const data = await response.json();\r\n        diagnostics.endpoints.models = true;\r\n        diagnostics.modelList = data.data || [];\r\n        diagnostics.details.push(`Available models: ${diagnostics.modelList.map(m => m.id).join(', ')}`);\r\n      } else {\r\n        // Try to get more error details\r\n        try {\r\n          const errorText = await response.text();\r\n          diagnostics.errors.push(`Server response: ${errorText}`);\r\n        } catch (e) {\r\n          diagnostics.errors.push('Could not read error response');\r\n        }\r\n      }\r\n    } catch (error) {\r\n      if (error.name === 'AbortError') {\r\n        diagnostics.errors.push('Connection timed out after 5 seconds');\r\n      } else if (error.message === 'Failed to fetch') {\r\n        diagnostics.errors.push(`Network error: Unable to reach ${testServerUrl}\\nPossible causes:\\n1. Server is not running\\n2. Network/firewall blocking connection\\n3. Incorrect server address`);\r\n      } else {\r\n        diagnostics.errors.push(`Connection error: ${error.message}`);\r\n      }\r\n    }\r\n\r\n    // Only test other endpoints if server is reachable\r\n    if (diagnostics.serverReachable && diagnostics.modelList.length > 0) {\r\n      const model = diagnostics.modelList[0].id;\r\n\r\n      // Test chat completions endpoint\r\n      try {\r\n        const chatResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\r\n          method: 'POST',\r\n          headers: DEFAULT_HEADERS,\r\n          body: JSON.stringify({\r\n            model,\r\n            messages: [{ role: 'user', content: 'Test' }],\r\n            stream: false,\r\n            max_tokens: 1\r\n          })\r\n        });\r\n        \r\n        diagnostics.endpoints.chat = chatResponse.ok;\r\n        diagnostics.details.push(`Chat endpoint: ${chatResponse.ok ? 'Available' : 'Not Available'}`);\r\n        \r\n        if (!chatResponse.ok) {\r\n          const errorText = await chatResponse.text();\r\n          diagnostics.errors.push(`Chat endpoint error: ${errorText}`);\r\n        }\r\n      } catch (error) {\r\n        diagnostics.errors.push(`Chat endpoint error: ${error.message}`);\r\n      }\r\n\r\n      // Test completions endpoint\r\n      try {\r\n        const completionsResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.completions}`, {\r\n          method: 'POST',\r\n          headers: DEFAULT_HEADERS,\r\n          body: JSON.stringify({\r\n            model,\r\n            prompt: 'Test',\r\n            stream: false,\r\n            max_tokens: 1\r\n          })\r\n        });\r\n        \r\n        diagnostics.endpoints.completions = completionsResponse.ok;\r\n        diagnostics.details.push(`Completions endpoint: ${completionsResponse.ok ? 'Available' : 'Not Available'}`);\r\n        \r\n        if (!completionsResponse.ok) {\r\n          const errorText = await completionsResponse.text();\r\n          diagnostics.errors.push(`Completions endpoint error: ${errorText}`);\r\n        }\r\n      } catch (error) {\r\n        diagnostics.errors.push(`Completions endpoint error: ${error.message}`);\r\n      }\r\n\r\n      // Test embeddings endpoint\r\n      try {\r\n        const embeddingModel = diagnostics.modelList.find(m => m.id.includes('embed'));\r\n        if (embeddingModel) {\r\n          const embeddingsResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.embeddings}`, {\r\n            method: 'POST',\r\n            headers: DEFAULT_HEADERS,\r\n            body: JSON.stringify({\r\n              model: embeddingModel.id,\r\n              input: 'Test'\r\n            })\r\n          });\r\n          \r\n          diagnostics.endpoints.embeddings = embeddingsResponse.ok;\r\n          diagnostics.details.push(`Embeddings endpoint: ${embeddingsResponse.ok ? 'Available' : 'Not Available'}`);\r\n          \r\n          if (!embeddingsResponse.ok) {\r\n            const errorText = await embeddingsResponse.text();\r\n            diagnostics.errors.push(`Embeddings endpoint error: ${errorText}`);\r\n          }\r\n        } else {\r\n          diagnostics.details.push('No embedding model available');\r\n        }\r\n      } catch (error) {\r\n        diagnostics.errors.push(`Embeddings endpoint error: ${error.message}`);\r\n      }\r\n    }\r\n  } catch (error) {\r\n    diagnostics.errors.push(`General error: ${error.message}`);\r\n  }\r\n\r\n  return diagnostics;\r\n}\r\n\r\n// Helper function to run all tests and log results\r\nasync function runConnectionTests() {\r\n  console.log('Starting LM Studio connection tests...');\r\n  \r\n  try {\r\n    // Run network diagnostics first\r\n    console.log('\\nRunning network diagnostics...');\r\n    const diagnostics = await runNetworkDiagnostics();\r\n    \r\n    if (!diagnostics.serverReachable) {\r\n      throw new Error(`Unable to connect to LM Studio server at ${testServerUrl}. Please check that:\\n1. LM Studio is running\\n2. Local Server is started\\n3. The server address is correct\\n\\nDiagnostics:\\n${diagnostics.details.join('\\n')}\\n\\nErrors:\\n${diagnostics.errors.join('\\n')}`);\r\n    }\r\n    \r\n    // Test 1: Basic Connection & Models List\r\n    console.log('\\nTesting models endpoint...');\r\n    const modelResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.models}`);\r\n    if (!modelResponse.ok) throw new Error(`Server returned ${modelResponse.status}`);\r\n    const modelData = await modelResponse.json();\r\n    console.log('Available models:', modelData.data);\r\n    if (!modelData.data || !modelData.data.length) {\r\n      throw new Error('No models available. Please load a model in LM Studio first.');\r\n    }\r\n    console.log('✅ Models endpoint test passed');\r\n\r\n    // Test 2: Simple Chat Request\r\n    console.log('\\nTesting chat completion...');\r\n    const chatResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\r\n      method: 'POST',\r\n      headers: { 'Content-Type': 'application/json' },\r\n      body: JSON.stringify({\r\n        model: modelData.data[0].id, // Use first available model\r\n        messages: [{ role: 'user', content: 'Hello' }],\r\n        stream: false\r\n      })\r\n    });\r\n    \r\n    if (!chatResponse.ok) {\r\n      const errorData = await chatResponse.text();\r\n      throw new Error(`Chat request failed: ${chatResponse.status}\\nResponse: ${errorData}`);\r\n    }\r\n    \r\n    const chatData = await chatResponse.json();\r\n    if (!chatData.choices || !chatData.choices.length) {\r\n      throw new Error('Chat response missing choices');\r\n    }\r\n    console.log('✅ Chat completion test passed');\r\n    console.log('Response:', chatData.choices[0]?.message?.content);\r\n\r\n    // Test 3: Streaming\r\n    console.log('\\nTesting streaming response...');\r\n    const streamResponse = await fetch(`${testServerUrl}${LM_STUDIO_ENDPOINTS.chat}`, {\r\n      method: 'POST',\r\n      headers: { 'Content-Type': 'application/json' },\r\n      body: JSON.stringify({\r\n        model: modelData.data[0].id, // Use first available model\r\n        messages: [{ role: 'user', content: 'Hi' }],\r\n        stream: true\r\n      })\r\n    });\r\n\r\n    if (!streamResponse.ok) {\r\n      const errorData = await streamResponse.text();\r\n      throw new Error(`Streaming request failed: ${streamResponse.status}\\nResponse: ${errorData}`);\r\n    }\r\n\r\n    console.log('Reading stream...');\r\n    const reader = streamResponse.body.getReader();\r\n    const decoder = new TextDecoder();\r\n    let streamContent = '';\r\n\r\n    while (true) {\r\n      const { done, value } = await reader.read();\r\n      if (done) break;\r\n      \r\n      const chunk = decoder.decode(value);\r\n      const lines = chunk.split('\\n');\r\n      \r\n      for (const line of lines) {\r\n        if (line.trim() && !line.includes('[DONE]')) {\r\n          try {\r\n            const jsonStr = line.replace(/^data: /, '');\r\n            const data = JSON.parse(jsonStr);\r\n            if (data.choices?.[0]?.delta?.content) {\r\n              streamContent += data.choices[0].delta.content;\r\n              process.stdout.write(data.choices[0].delta.content);\r\n            }\r\n          } catch (e) {\r\n            // Ignore parse errors for non-data lines\r\n          }\r\n        }\r\n      }\r\n    }\r\n    console.log('\\n✅ Streaming test passed');\r\n\r\n    console.log('\\n✅ All tests passed successfully!');\r\n    return true;\r\n  } catch (error) {\r\n    console.error('\\n❌ Test failed:', error.message);\r\n    console.error('Error details:', error);\r\n    return false;\r\n  }\r\n}\r\n\r\ndescribe('ChatConnection', () => {\r\n  beforeEach(() => {\r\n    // Reset fetch mocks before each test\r\n    global.fetch = jest.fn();\r\n    jest.useFakeTimers();\r\n  });\r\n\r\n  afterEach(() => {\r\n    jest.useRealTimers();\r\n  });\r\n\r\n  it('should run network diagnostics successfully', async () => {\r\n    // Mock successful responses\r\n    global.fetch.mockImplementation((url) => {\r\n      if (url.includes('/v1/models')) {\r\n        return Promise.resolve({\r\n          ok: true,\r\n          json: () => Promise.resolve({ data: [{ id: 'test-model' }] }),\r\n          text: () => Promise.resolve(''),\r\n          status: 200,\r\n          statusText: 'OK'\r\n        });\r\n      }\r\n      return Promise.resolve({\r\n        ok: true,\r\n        json: () => Promise.resolve({}),\r\n        text: () => Promise.resolve(''),\r\n        status: 200,\r\n        statusText: 'OK'\r\n      });\r\n    });\r\n\r\n    const diagnostics = await runNetworkDiagnostics();\r\n    expect(diagnostics.serverReachable).toBe(true);\r\n    expect(diagnostics.endpoints.models).toBe(true);\r\n    expect(diagnostics.modelList).toHaveLength(1);\r\n    expect(diagnostics.modelList[0].id).toBe('test-model');\r\n  });\r\n\r\n  it('should handle server connection failure', async () => {\r\n    // Mock failed connection\r\n    global.fetch.mockRejectedValue(new Error('Failed to fetch'));\r\n\r\n    const diagnostics = await runNetworkDiagnostics();\r\n    expect(diagnostics.serverReachable).toBe(false);\r\n    expect(diagnostics.errors).toHaveLength(1);\r\n    expect(diagnostics.errors[0]).toContain('Network error: Unable to reach');\r\n  });\r\n\r\n  it('should handle timeout', async () => {\r\n    // Mock timeout\r\n    global.fetch.mockImplementation((_url, options) => {\r\n      return new Promise((resolve, reject) => {\r\n        const timeoutId = setTimeout(() => {\r\n          resolve({\r\n            ok: false,\r\n            status: 408,\r\n            statusText: 'Request Timeout'\r\n          });\r\n        }, 6000);\r\n\r\n        // Handle abort signal\r\n        if (options?.signal) {\r\n          options.signal.addEventListener('abort', () => {\r\n            clearTimeout(timeoutId);\r\n            reject(new Error('AbortError'));\r\n          });\r\n        }\r\n      });\r\n    });\r\n\r\n    const diagnosticsPromise = runNetworkDiagnostics();\r\n    jest.advanceTimersByTime(5000); // Advance just to the timeout\r\n    const diagnostics = await diagnosticsPromise;\r\n\r\n    expect(diagnostics.serverReachable).toBe(false);\r\n    expect(diagnostics.errors).toHaveLength(1);\r\n    expect(diagnostics.errors[0]).toBe('Connection timed out after 5 seconds');\r\n  });\r\n});\r\n\r\nmodule.exports = {\r\n  runConnectionTests,\r\n  runNetworkDiagnostics\r\n}; "],"mappings":"AAAA;AACA,MAAMA,aAAa,GAAG,2BAA2B;AAEjD,MAAMC,mBAAmB,GAAG;EAC1BC,MAAM,EAAE,YAAY;EACpBC,IAAI,EAAE,sBAAsB;EAC5BC,WAAW,EAAE,iBAAiB;EAC9BC,UAAU,EAAE;AACd,CAAC;AAED,MAAMC,eAAe,GAAG;EACtB,QAAQ,EAAE,kBAAkB;EAC5B,cAAc,EAAE;AAClB,CAAC;;AAED;AACA,eAAeC,qBAAqBA,CAAA,EAAG;EACrC,MAAMC,WAAW,GAAG;IAClBC,eAAe,EAAE,KAAK;IACtBC,SAAS,EAAE;MACTR,MAAM,EAAE,KAAK;MACbC,IAAI,EAAE,KAAK;MACXC,WAAW,EAAE,KAAK;MAClBC,UAAU,EAAE;IACd,CAAC;IACDM,SAAS,EAAE,EAAE;IACbC,OAAO,EAAE,EAAE;IACXC,MAAM,EAAE;EACV,CAAC;EAED,IAAI;IACF;IACA,MAAMC,UAAU,GAAG,IAAIC,eAAe,CAAC,CAAC;IACxC,MAAMC,SAAS,GAAGC,UAAU,CAAC,MAAMH,UAAU,CAACI,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC;IAE5D,IAAI;MACF;MACA,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACC,MAAM,EAAE,EAAE;QAC5EmB,MAAM,EAAE,KAAK;QACbC,OAAO,EAAEhB,eAAe;QACxBiB,MAAM,EAAET,UAAU,CAACS;MACrB,CAAC,CAAC;MAEFC,YAAY,CAACR,SAAS,CAAC;MAEvBR,WAAW,CAACC,eAAe,GAAGU,QAAQ,CAACM,EAAE;MACzCjB,WAAW,CAACI,OAAO,CAACc,IAAI,CAAC,sBAAsBP,QAAQ,CAACM,EAAE,GAAG,SAAS,GAAG,QAAQ,EAAE,CAAC;MACpFjB,WAAW,CAACI,OAAO,CAACc,IAAI,CAAC,oBAAoBP,QAAQ,CAACQ,MAAM,IAAIR,QAAQ,CAACS,UAAU,EAAE,CAAC;MAEtF,IAAIT,QAAQ,CAACM,EAAE,EAAE;QACf,MAAMI,IAAI,GAAG,MAAMV,QAAQ,CAACW,IAAI,CAAC,CAAC;QAClCtB,WAAW,CAACE,SAAS,CAACR,MAAM,GAAG,IAAI;QACnCM,WAAW,CAACG,SAAS,GAAGkB,IAAI,CAACA,IAAI,IAAI,EAAE;QACvCrB,WAAW,CAACI,OAAO,CAACc,IAAI,CAAC,qBAAqBlB,WAAW,CAACG,SAAS,CAACoB,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACC,EAAE,CAAC,CAACC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC;MAClG,CAAC,MAAM;QACL;QACA,IAAI;UACF,MAAMC,SAAS,GAAG,MAAMhB,QAAQ,CAACiB,IAAI,CAAC,CAAC;UACvC5B,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,oBAAoBS,SAAS,EAAE,CAAC;QAC1D,CAAC,CAAC,OAAOE,CAAC,EAAE;UACV7B,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,+BAA+B,CAAC;QAC1D;MACF;IACF,CAAC,CAAC,OAAOY,KAAK,EAAE;MACd,IAAIA,KAAK,CAACC,IAAI,KAAK,YAAY,EAAE;QAC/B/B,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,sCAAsC,CAAC;MACjE,CAAC,MAAM,IAAIY,KAAK,CAACE,OAAO,KAAK,iBAAiB,EAAE;QAC9ChC,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,kCAAkC1B,aAAa,oHAAoH,CAAC;MAC9L,CAAC,MAAM;QACLQ,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,qBAAqBY,KAAK,CAACE,OAAO,EAAE,CAAC;MAC/D;IACF;;IAEA;IACA,IAAIhC,WAAW,CAACC,eAAe,IAAID,WAAW,CAACG,SAAS,CAAC8B,MAAM,GAAG,CAAC,EAAE;MACnE,MAAMC,KAAK,GAAGlC,WAAW,CAACG,SAAS,CAAC,CAAC,CAAC,CAACsB,EAAE;;MAEzC;MACA,IAAI;QACF,MAAMU,YAAY,GAAG,MAAMvB,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACE,IAAI,EAAE,EAAE;UAC9EkB,MAAM,EAAE,MAAM;UACdC,OAAO,EAAEhB,eAAe;UACxBsC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;YACnBJ,KAAK;YACLK,QAAQ,EAAE,CAAC;cAAEC,IAAI,EAAE,MAAM;cAAEC,OAAO,EAAE;YAAO,CAAC,CAAC;YAC7CC,MAAM,EAAE,KAAK;YACbC,UAAU,EAAE;UACd,CAAC;QACH,CAAC,CAAC;QAEF3C,WAAW,CAACE,SAAS,CAACP,IAAI,GAAGwC,YAAY,CAAClB,EAAE;QAC5CjB,WAAW,CAACI,OAAO,CAACc,IAAI,CAAC,kBAAkBiB,YAAY,CAAClB,EAAE,GAAG,WAAW,GAAG,eAAe,EAAE,CAAC;QAE7F,IAAI,CAACkB,YAAY,CAAClB,EAAE,EAAE;UACpB,MAAMU,SAAS,GAAG,MAAMQ,YAAY,CAACP,IAAI,CAAC,CAAC;UAC3C5B,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,wBAAwBS,SAAS,EAAE,CAAC;QAC9D;MACF,CAAC,CAAC,OAAOG,KAAK,EAAE;QACd9B,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,wBAAwBY,KAAK,CAACE,OAAO,EAAE,CAAC;MAClE;;MAEA;MACA,IAAI;QACF,MAAMY,mBAAmB,GAAG,MAAMhC,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACG,WAAW,EAAE,EAAE;UAC5FiB,MAAM,EAAE,MAAM;UACdC,OAAO,EAAEhB,eAAe;UACxBsC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;YACnBJ,KAAK;YACLW,MAAM,EAAE,MAAM;YACdH,MAAM,EAAE,KAAK;YACbC,UAAU,EAAE;UACd,CAAC;QACH,CAAC,CAAC;QAEF3C,WAAW,CAACE,SAAS,CAACN,WAAW,GAAGgD,mBAAmB,CAAC3B,EAAE;QAC1DjB,WAAW,CAACI,OAAO,CAACc,IAAI,CAAC,yBAAyB0B,mBAAmB,CAAC3B,EAAE,GAAG,WAAW,GAAG,eAAe,EAAE,CAAC;QAE3G,IAAI,CAAC2B,mBAAmB,CAAC3B,EAAE,EAAE;UAC3B,MAAMU,SAAS,GAAG,MAAMiB,mBAAmB,CAAChB,IAAI,CAAC,CAAC;UAClD5B,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,+BAA+BS,SAAS,EAAE,CAAC;QACrE;MACF,CAAC,CAAC,OAAOG,KAAK,EAAE;QACd9B,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,+BAA+BY,KAAK,CAACE,OAAO,EAAE,CAAC;MACzE;;MAEA;MACA,IAAI;QACF,MAAMc,cAAc,GAAG9C,WAAW,CAACG,SAAS,CAAC4C,IAAI,CAACvB,CAAC,IAAIA,CAAC,CAACC,EAAE,CAACuB,QAAQ,CAAC,OAAO,CAAC,CAAC;QAC9E,IAAIF,cAAc,EAAE;UAClB,MAAMG,kBAAkB,GAAG,MAAMrC,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACI,UAAU,EAAE,EAAE;YAC1FgB,MAAM,EAAE,MAAM;YACdC,OAAO,EAAEhB,eAAe;YACxBsC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;cACnBJ,KAAK,EAAEY,cAAc,CAACrB,EAAE;cACxByB,KAAK,EAAE;YACT,CAAC;UACH,CAAC,CAAC;UAEFlD,WAAW,CAACE,SAAS,CAACL,UAAU,GAAGoD,kBAAkB,CAAChC,EAAE;UACxDjB,WAAW,CAACI,OAAO,CAACc,IAAI,CAAC,wBAAwB+B,kBAAkB,CAAChC,EAAE,GAAG,WAAW,GAAG,eAAe,EAAE,CAAC;UAEzG,IAAI,CAACgC,kBAAkB,CAAChC,EAAE,EAAE;YAC1B,MAAMU,SAAS,GAAG,MAAMsB,kBAAkB,CAACrB,IAAI,CAAC,CAAC;YACjD5B,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,8BAA8BS,SAAS,EAAE,CAAC;UACpE;QACF,CAAC,MAAM;UACL3B,WAAW,CAACI,OAAO,CAACc,IAAI,CAAC,8BAA8B,CAAC;QAC1D;MACF,CAAC,CAAC,OAAOY,KAAK,EAAE;QACd9B,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,8BAA8BY,KAAK,CAACE,OAAO,EAAE,CAAC;MACxE;IACF;EACF,CAAC,CAAC,OAAOF,KAAK,EAAE;IACd9B,WAAW,CAACK,MAAM,CAACa,IAAI,CAAC,kBAAkBY,KAAK,CAACE,OAAO,EAAE,CAAC;EAC5D;EAEA,OAAOhC,WAAW;AACpB;;AAEA;AACA,eAAemD,kBAAkBA,CAAA,EAAG;EAClCC,OAAO,CAACC,GAAG,CAAC,wCAAwC,CAAC;EAErD,IAAI;IAAA,IAAAC,kBAAA,EAAAC,qBAAA;IACF;IACAH,OAAO,CAACC,GAAG,CAAC,kCAAkC,CAAC;IAC/C,MAAMrD,WAAW,GAAG,MAAMD,qBAAqB,CAAC,CAAC;IAEjD,IAAI,CAACC,WAAW,CAACC,eAAe,EAAE;MAChC,MAAM,IAAIuD,KAAK,CAAC,4CAA4ChE,aAAa,gIAAgIQ,WAAW,CAACI,OAAO,CAACsB,IAAI,CAAC,IAAI,CAAC,gBAAgB1B,WAAW,CAACK,MAAM,CAACqB,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC;IACzR;;IAEA;IACA0B,OAAO,CAACC,GAAG,CAAC,8BAA8B,CAAC;IAC3C,MAAMI,aAAa,GAAG,MAAM7C,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACC,MAAM,EAAE,CAAC;IAClF,IAAI,CAAC+D,aAAa,CAACxC,EAAE,EAAE,MAAM,IAAIuC,KAAK,CAAC,mBAAmBC,aAAa,CAACtC,MAAM,EAAE,CAAC;IACjF,MAAMuC,SAAS,GAAG,MAAMD,aAAa,CAACnC,IAAI,CAAC,CAAC;IAC5C8B,OAAO,CAACC,GAAG,CAAC,mBAAmB,EAAEK,SAAS,CAACrC,IAAI,CAAC;IAChD,IAAI,CAACqC,SAAS,CAACrC,IAAI,IAAI,CAACqC,SAAS,CAACrC,IAAI,CAACY,MAAM,EAAE;MAC7C,MAAM,IAAIuB,KAAK,CAAC,8DAA8D,CAAC;IACjF;IACAJ,OAAO,CAACC,GAAG,CAAC,+BAA+B,CAAC;;IAE5C;IACAD,OAAO,CAACC,GAAG,CAAC,8BAA8B,CAAC;IAC3C,MAAMlB,YAAY,GAAG,MAAMvB,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACE,IAAI,EAAE,EAAE;MAC9EkB,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QAAE,cAAc,EAAE;MAAmB,CAAC;MAC/CsB,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBJ,KAAK,EAAEwB,SAAS,CAACrC,IAAI,CAAC,CAAC,CAAC,CAACI,EAAE;QAAE;QAC7Bc,QAAQ,EAAE,CAAC;UAAEC,IAAI,EAAE,MAAM;UAAEC,OAAO,EAAE;QAAQ,CAAC,CAAC;QAC9CC,MAAM,EAAE;MACV,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAACP,YAAY,CAAClB,EAAE,EAAE;MACpB,MAAM0C,SAAS,GAAG,MAAMxB,YAAY,CAACP,IAAI,CAAC,CAAC;MAC3C,MAAM,IAAI4B,KAAK,CAAC,wBAAwBrB,YAAY,CAAChB,MAAM,eAAewC,SAAS,EAAE,CAAC;IACxF;IAEA,MAAMC,QAAQ,GAAG,MAAMzB,YAAY,CAACb,IAAI,CAAC,CAAC;IAC1C,IAAI,CAACsC,QAAQ,CAACC,OAAO,IAAI,CAACD,QAAQ,CAACC,OAAO,CAAC5B,MAAM,EAAE;MACjD,MAAM,IAAIuB,KAAK,CAAC,+BAA+B,CAAC;IAClD;IACAJ,OAAO,CAACC,GAAG,CAAC,+BAA+B,CAAC;IAC5CD,OAAO,CAACC,GAAG,CAAC,WAAW,GAAAC,kBAAA,GAAEM,QAAQ,CAACC,OAAO,CAAC,CAAC,CAAC,cAAAP,kBAAA,wBAAAC,qBAAA,GAAnBD,kBAAA,CAAqBtB,OAAO,cAAAuB,qBAAA,uBAA5BA,qBAAA,CAA8Bd,OAAO,CAAC;;IAE/D;IACAW,OAAO,CAACC,GAAG,CAAC,iCAAiC,CAAC;IAC9C,MAAMS,cAAc,GAAG,MAAMlD,KAAK,CAAC,GAAGpB,aAAa,GAAGC,mBAAmB,CAACE,IAAI,EAAE,EAAE;MAChFkB,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QAAE,cAAc,EAAE;MAAmB,CAAC;MAC/CsB,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBJ,KAAK,EAAEwB,SAAS,CAACrC,IAAI,CAAC,CAAC,CAAC,CAACI,EAAE;QAAE;QAC7Bc,QAAQ,EAAE,CAAC;UAAEC,IAAI,EAAE,MAAM;UAAEC,OAAO,EAAE;QAAK,CAAC,CAAC;QAC3CC,MAAM,EAAE;MACV,CAAC;IACH,CAAC,CAAC;IAEF,IAAI,CAACoB,cAAc,CAAC7C,EAAE,EAAE;MACtB,MAAM0C,SAAS,GAAG,MAAMG,cAAc,CAAClC,IAAI,CAAC,CAAC;MAC7C,MAAM,IAAI4B,KAAK,CAAC,6BAA6BM,cAAc,CAAC3C,MAAM,eAAewC,SAAS,EAAE,CAAC;IAC/F;IAEAP,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;IAChC,MAAMU,MAAM,GAAGD,cAAc,CAAC1B,IAAI,CAAC4B,SAAS,CAAC,CAAC;IAC9C,MAAMC,OAAO,GAAG,IAAIC,WAAW,CAAC,CAAC;IACjC,IAAIC,aAAa,GAAG,EAAE;IAEtB,OAAO,IAAI,EAAE;MACX,MAAM;QAAEC,IAAI;QAAEC;MAAM,CAAC,GAAG,MAAMN,MAAM,CAACO,IAAI,CAAC,CAAC;MAC3C,IAAIF,IAAI,EAAE;MAEV,MAAMG,KAAK,GAAGN,OAAO,CAACO,MAAM,CAACH,KAAK,CAAC;MACnC,MAAMI,KAAK,GAAGF,KAAK,CAACG,KAAK,CAAC,IAAI,CAAC;MAE/B,KAAK,MAAMC,IAAI,IAAIF,KAAK,EAAE;QACxB,IAAIE,IAAI,CAACC,IAAI,CAAC,CAAC,IAAI,CAACD,IAAI,CAAC3B,QAAQ,CAAC,QAAQ,CAAC,EAAE;UAC3C,IAAI;YAAA,IAAA6B,aAAA,EAAAC,cAAA,EAAAC,oBAAA;YACF,MAAMC,OAAO,GAAGL,IAAI,CAACM,OAAO,CAAC,SAAS,EAAE,EAAE,CAAC;YAC3C,MAAM5D,IAAI,GAAGgB,IAAI,CAAC6C,KAAK,CAACF,OAAO,CAAC;YAChC,KAAAH,aAAA,GAAIxD,IAAI,CAACwC,OAAO,cAAAgB,aAAA,gBAAAC,cAAA,GAAZD,aAAA,CAAe,CAAC,CAAC,cAAAC,cAAA,gBAAAC,oBAAA,GAAjBD,cAAA,CAAmBK,KAAK,cAAAJ,oBAAA,eAAxBA,oBAAA,CAA0BtC,OAAO,EAAE;cACrC0B,aAAa,IAAI9C,IAAI,CAACwC,OAAO,CAAC,CAAC,CAAC,CAACsB,KAAK,CAAC1C,OAAO;cAC9C2C,OAAO,CAACC,MAAM,CAACC,KAAK,CAACjE,IAAI,CAACwC,OAAO,CAAC,CAAC,CAAC,CAACsB,KAAK,CAAC1C,OAAO,CAAC;YACrD;UACF,CAAC,CAAC,OAAOZ,CAAC,EAAE;YACV;UAAA;QAEJ;MACF;IACF;IACAuB,OAAO,CAACC,GAAG,CAAC,2BAA2B,CAAC;IAExCD,OAAO,CAACC,GAAG,CAAC,oCAAoC,CAAC;IACjD,OAAO,IAAI;EACb,CAAC,CAAC,OAAOvB,KAAK,EAAE;IACdsB,OAAO,CAACtB,KAAK,CAAC,kBAAkB,EAAEA,KAAK,CAACE,OAAO,CAAC;IAChDoB,OAAO,CAACtB,KAAK,CAAC,gBAAgB,EAAEA,KAAK,CAAC;IACtC,OAAO,KAAK;EACd;AACF;AAEAyD,QAAQ,CAAC,gBAAgB,EAAE,MAAM;EAAA,IAAAC,EAAA,GAAAC,YAAA;IAAAC,GAAA,GAAAD,YAAA;EAC/BD,EAAA,CAAAG,UAAU,CAAAH,EAAA,CAAC,MAAM;IAAAA,EAAA;IACf;IACAI,MAAM,CAAChF,KAAK,GAAGiF,IAAI,CAACC,EAAE,CAAC,CAAC;IACxBD,IAAI,CAACE,aAAa,CAAC,CAAC;EACtB,CAAC,wCAAC;EAEFL,GAAA,CAAAM,SAAS,CAAAN,GAAA,CAAC,MAAM;IAAAA,GAAA;IACdG,IAAI,CAACI,aAAa,CAAC,CAAC;EACtB,CAAC,wCAAC;EAEFC,EAAE,CAAC,6CAA6C,EAAE,YAAY;IAC5D;IACAN,MAAM,CAAChF,KAAK,CAACuF,kBAAkB,CAAEC,GAAG,IAAK;MACvC,IAAIA,GAAG,CAACpD,QAAQ,CAAC,YAAY,CAAC,EAAE;QAC9B,OAAOqD,OAAO,CAACC,OAAO,CAAC;UACrBrF,EAAE,EAAE,IAAI;UACRK,IAAI,EAAEA,CAAA,KAAM+E,OAAO,CAACC,OAAO,CAAC;YAAEjF,IAAI,EAAE,CAAC;cAAEI,EAAE,EAAE;YAAa,CAAC;UAAE,CAAC,CAAC;UAC7DG,IAAI,EAAEA,CAAA,KAAMyE,OAAO,CAACC,OAAO,CAAC,EAAE,CAAC;UAC/BnF,MAAM,EAAE,GAAG;UACXC,UAAU,EAAE;QACd,CAAC,CAAC;MACJ;MACA,OAAOiF,OAAO,CAACC,OAAO,CAAC;QACrBrF,EAAE,EAAE,IAAI;QACRK,IAAI,EAAEA,CAAA,KAAM+E,OAAO,CAACC,OAAO,CAAC,CAAC,CAAC,CAAC;QAC/B1E,IAAI,EAAEA,CAAA,KAAMyE,OAAO,CAACC,OAAO,CAAC,EAAE,CAAC;QAC/BnF,MAAM,EAAE,GAAG;QACXC,UAAU,EAAE;MACd,CAAC,CAAC;IACJ,CAAC,CAAC;IAEF,MAAMpB,WAAW,GAAG,MAAMD,qBAAqB,CAAC,CAAC;IACjDwG,MAAM,CAACvG,WAAW,CAACC,eAAe,CAAC,CAACuG,IAAI,CAAC,IAAI,CAAC;IAC9CD,MAAM,CAACvG,WAAW,CAACE,SAAS,CAACR,MAAM,CAAC,CAAC8G,IAAI,CAAC,IAAI,CAAC;IAC/CD,MAAM,CAACvG,WAAW,CAACG,SAAS,CAAC,CAACsG,YAAY,CAAC,CAAC,CAAC;IAC7CF,MAAM,CAACvG,WAAW,CAACG,SAAS,CAAC,CAAC,CAAC,CAACsB,EAAE,CAAC,CAAC+E,IAAI,CAAC,YAAY,CAAC;EACxD,CAAC,CAAC;EAEFN,EAAE,CAAC,yCAAyC,EAAE,YAAY;IACxD;IACAN,MAAM,CAAChF,KAAK,CAAC8F,iBAAiB,CAAC,IAAIlD,KAAK,CAAC,iBAAiB,CAAC,CAAC;IAE5D,MAAMxD,WAAW,GAAG,MAAMD,qBAAqB,CAAC,CAAC;IACjDwG,MAAM,CAACvG,WAAW,CAACC,eAAe,CAAC,CAACuG,IAAI,CAAC,KAAK,CAAC;IAC/CD,MAAM,CAACvG,WAAW,CAACK,MAAM,CAAC,CAACoG,YAAY,CAAC,CAAC,CAAC;IAC1CF,MAAM,CAACvG,WAAW,CAACK,MAAM,CAAC,CAAC,CAAC,CAAC,CAACsG,SAAS,CAAC,gCAAgC,CAAC;EAC3E,CAAC,CAAC;EAEFT,EAAE,CAAC,uBAAuB,EAAE,YAAY;IACtC;IACAN,MAAM,CAAChF,KAAK,CAACuF,kBAAkB,CAAC,CAACS,IAAI,EAAEC,OAAO,KAAK;MACjD,OAAO,IAAIR,OAAO,CAAC,CAACC,OAAO,EAAEQ,MAAM,KAAK;QACtC,MAAMtG,SAAS,GAAGC,UAAU,CAAC,MAAM;UACjC6F,OAAO,CAAC;YACNrF,EAAE,EAAE,KAAK;YACTE,MAAM,EAAE,GAAG;YACXC,UAAU,EAAE;UACd,CAAC,CAAC;QACJ,CAAC,EAAE,IAAI,CAAC;;QAER;QACA,IAAIyF,OAAO,aAAPA,OAAO,eAAPA,OAAO,CAAE9F,MAAM,EAAE;UACnB8F,OAAO,CAAC9F,MAAM,CAACgG,gBAAgB,CAAC,OAAO,EAAE,MAAM;YAC7C/F,YAAY,CAACR,SAAS,CAAC;YACvBsG,MAAM,CAAC,IAAItD,KAAK,CAAC,YAAY,CAAC,CAAC;UACjC,CAAC,CAAC;QACJ;MACF,CAAC,CAAC;IACJ,CAAC,CAAC;IAEF,MAAMwD,kBAAkB,GAAGjH,qBAAqB,CAAC,CAAC;IAClD8F,IAAI,CAACoB,mBAAmB,CAAC,IAAI,CAAC,CAAC,CAAC;IAChC,MAAMjH,WAAW,GAAG,MAAMgH,kBAAkB;IAE5CT,MAAM,CAACvG,WAAW,CAACC,eAAe,CAAC,CAACuG,IAAI,CAAC,KAAK,CAAC;IAC/CD,MAAM,CAACvG,WAAW,CAACK,MAAM,CAAC,CAACoG,YAAY,CAAC,CAAC,CAAC;IAC1CF,MAAM,CAACvG,WAAW,CAACK,MAAM,CAAC,CAAC,CAAC,CAAC,CAACmG,IAAI,CAAC,sCAAsC,CAAC;EAC5E,CAAC,CAAC;AACJ,CAAC,CAAC;AAEFU,MAAM,CAACC,OAAO,GAAG;EACfhE,kBAAkB;EAClBpD;AACF,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}